---
id: "0003"
title: "Phase V Cloud Deployment Plan"
stage: "plan"
date: "2025-12-29"
surface: "agent"
model: "claude-opus-4-5-20251101"
feature: "001-phase-v-cloud-deployment"
branch: "001-phase-v-cloud-deployment"
user: "human"
command: "/sp.plan"
labels: ["phase-v","cloud-deployment","architecture","dapr","kafka"]
links:
  spec: "specs/001-phase-v-cloud-deployment/spec.md"
  ticket: "null"
  adr: "null"
  pr: "null"
files:
  - specs/001-phase-v-cloud-deployment/plan.md
  - specs/001-phase-v-cloud-deployment/research.md
  - specs/001-phase-v-cloud-deployment/data-model.md
  - specs/001-phase-v-cloud-deployment/quickstart.md
  - specs/001-phase-v-cloud-deployment/contracts/openapi.yaml
  - specs/001-phase-v-cloud-deployment/contracts/events.yaml
tests: []
---

## Prompt

PHASE V IMPLEMENTATION PLAN

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MILESTONE 1: Advanced Features Implementation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 1.1: Database Schema Updates
â”œâ”€ Add priority column (enum: low, medium, high)
â”œâ”€ Add tags column (text[] with GIN index)
â”œâ”€ Add recurrence column (enum: none, daily, weekly, monthly)
â”œâ”€ Add due_date column (timestamp with timezone)
â”œâ”€ Add reminder_offset column (interval: 1 day, 1 hour, etc.)
â””â”€ Add parent_task_id column (for recurring task chains)

Phase 1.2: MCP Tools Extension
â”œâ”€ update_task_priority(task_id, priority)
â”œâ”€ add_tags(task_id, tags[])
â”œâ”€ remove_tags(task_id, tags[])
â”œâ”€ search_tasks(query, filters, sort_by, limit, offset)
â”œâ”€ create_recurring_task(title, recurrence, due_date)
â””â”€ schedule_reminder(task_id, remind_at)

Phase 1.3: Gemini Chatbot Enhancement
â”œâ”€ Update system prompt with new tool descriptions
â”œâ”€ Add natural language parsing for:
â”‚   â”œâ”€ "high priority" â†’ priority=high
â”‚   â”œâ”€ "#work #urgent" â†’ tags=['work', 'urgent']
â”‚   â”œâ”€ "every Monday" â†’ recurrence=weekly
â”‚   â””â”€ "remind me 1 day before" â†’ reminder_offset=1 day
â”œâ”€ Implement conversation state management
â””â”€ Add error handling for Gemini API rate limits

Phase 1.4: Testing
â”œâ”€ Unit tests for new MCP tools
â”œâ”€ Integration tests: Gemini â†’ MCP â†’ Database
â””â”€ Load test: 50 concurrent chatbot sessions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MILESTONE 2: Event-Driven Architecture
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 2.1: Kafka Setup (Local - Strimzi)
â”œâ”€ Install Strimzi operator on Minikube
â”œâ”€ Create Kafka cluster (1 broker, ephemeral storage)
â”œâ”€ Create topics:
â”‚   â”œâ”€ task-events (partitions: 3, replication: 1)
â”‚   â”œâ”€ reminders (partitions: 3, replication: 1)
â”‚   â””â”€ task-updates (partitions: 3, replication: 1)
â””â”€ Verify with Kafka console consumer

Phase 2.2: Backend Event Publisher
â”œâ”€ Add Kafka producer to Backend API
â”œâ”€ Publish events on:
â”‚   â”œâ”€ Task created â†’ task-events (event_type: created)
â”‚   â”œâ”€ Task updated â†’ task-events (event_type: updated)
â”‚   â”œâ”€ Task completed â†’ task-events (event_type: completed)
â”‚   â”œâ”€ Task deleted â†’ task-events (event_type: deleted)
â”‚   â””â”€ Reminder scheduled â†’ reminders (remind_at timestamp)
â””â”€ Include correlation_id in all events (for tracing)

Phase 2.3: Recurring Task Service
â”œâ”€ Create new microservice (Python FastAPI)
â”œâ”€ Kafka consumer for "task-events" topic
â”œâ”€ Logic:
â”‚   â”œâ”€ Filter for event_type == "completed"
â”‚   â”œâ”€ Check if task has recurrence != "none"
â”‚   â”œâ”€ Calculate next due_date based on recurrence type
â”‚   â”œâ”€ Create new task via Backend API (HTTP call)
â”‚   â””â”€ Set parent_task_id to maintain chain
â””â”€ Containerize and prepare K8s deployment

Phase 2.4: Notification Service
â”œâ”€ Create new microservice (Python FastAPI)
â”œâ”€ Kafka consumer for "reminders" topic
â”œâ”€ Logic:
â”‚   â”œâ”€ Receive reminder event
â”‚   â”œâ”€ Fetch task details from database
â”‚   â”œâ”€ Send notification (WebSocket/Email/Push)
â”‚   â””â”€ Mark reminder as sent (prevent duplicates)
â”œâ”€ Implement retry logic (3 attempts with backoff)
â””â”€ Containerize and prepare K8s deployment

Phase 2.5: Audit Service (Optional)
â”œâ”€ Create microservice for audit logging
â”œâ”€ Kafka consumer for "task-events" topic
â”œâ”€ Store all events in separate audit_log table
â””â”€ Useful for debugging and compliance

Phase 2.6: Testing
â”œâ”€ Integration test: Complete task â†’ new recurring task created
â”œâ”€ Integration test: Schedule reminder â†’ notification sent
â”œâ”€ Chaos test: Kill Kafka broker â†’ verify consumer recovery
â””â”€ Load test: 1000 events/second throughput

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MILESTONE 3: Dapr Integration
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 3.1: Dapr Installation
â”œâ”€ Install Dapr CLI: curl -fsSL https://dapr.io/install.sh | bash
â”œâ”€ Initialize Dapr on Minikube: dapr init -k
â”œâ”€ Verify installation: kubectl get pods -n dapr-system
â””â”€ Install Dapr Dashboard: dapr dashboard -k

Phase 3.2: Dapr Components Configuration
â”œâ”€ Create dapr-components/ folder
â”œâ”€ kafka-pubsub.yaml (pubsub.kafka)
â”‚   â”œâ”€ Connect to Strimzi Kafka cluster
â”‚   â””â”€ Define topics (task-events, reminders, task-updates)
â”œâ”€ statestore.yaml (state.postgresql)
â”‚   â”œâ”€ Connect to Neon PostgreSQL
â”‚   â””â”€ Table name: dapr_state
â”œâ”€ kubernetes-secrets.yaml (secretstores.kubernetes)
â”‚   â””â”€ Access K8s secrets (Gemini API key, DB credentials)
â””â”€ Apply: kubectl apply -f dapr-components/

Phase 3.3: Refactor Backend to Use Dapr
â”œâ”€ Remove direct Kafka client (kafka-python)
â”œâ”€ Publish events via Dapr HTTP API:
â”‚   POST http://localhost:3500/v1.0/publish/kafka-pubsub/task-events
â”œâ”€ Store conversation state via Dapr:
â”‚   POST http://localhost:3500/v1.0/state/statestore
â”œâ”€ Retrieve secrets via Dapr:
â”‚   GET http://localhost:3500/v1.0/secrets/kubernetes-secrets/gemini-key
â””â”€ Update Dockerfile and K8s deployment with Dapr annotations

Phase 3.4: Refactor Services to Use Dapr
â”œâ”€ Recurring Task Service:
â”‚   â””â”€ Subscribe to events via Dapr:
â”‚       POST http://localhost:3500/v1.0/subscribe
â”œâ”€ Notification Service:
â”‚   â””â”€ Subscribe to events via Dapr
â”œâ”€ Frontend:
â”‚   â””â”€ Call Backend via Dapr service invocation:
â”‚       POST http://localhost:3500/v1.0/invoke/backend-service/method/api/chat
â””â”€ Update all K8s deployments with Dapr sidecar annotations

Phase 3.5: Dapr Jobs API for Reminders
â”œâ”€ Remove cron-based polling (if implemented)
â”œâ”€ Schedule reminders via Dapr Jobs API:
â”‚   POST http://localhost:3500/v1.0-alpha1/jobs/reminder-{task_id}
â”‚   { "dueTime": "2025-12-30T10:00:00Z", "data": {...} }
â”œâ”€ Implement callback endpoint:
â”‚   @app.post("/api/jobs/trigger")
â”‚   async def handle_job_trigger(request: Request):
â”‚       # Publish to reminders topic
â””â”€ Test: Schedule job â†’ verify callback fires at exact time

Phase 3.6: Testing
â”œâ”€ Test Dapr Pub/Sub: Publish event â†’ verify consumption
â”œâ”€ Test Dapr State: Save state â†’ retrieve â†’ verify persistence
â”œâ”€ Test Dapr Service Invocation: Frontend â†’ Backend call
â”œâ”€ Test Dapr Jobs: Schedule job â†’ verify callback
â””â”€ Check Dapr Dashboard for metrics and tracing

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MILESTONE 4: Local Deployment (Minikube)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 4.1: Minikube Setup
â”œâ”€ Start Minikube: minikube start --cpus=4 --memory=8192
â”œâ”€ Enable addons: minikube addons enable ingress
â”œâ”€ Enable Dapr: dapr init -k
â””â”€ Install Strimzi Kafka (from Milestone 2)

Phase 4.2: Kubernetes Manifests
â”œâ”€ Update Phase IV Helm charts for Phase V services
â”œâ”€ Add Dapr sidecar annotations to all deployments:
â”‚   dapr.io/enabled: "true"
â”‚   dapr.io/app-id: "backend-service"
â”‚   dapr.io/app-port: "8000"
â”œâ”€ Create secrets:
â”‚   â”œâ”€ gemini-api-key
â”‚   â”œâ”€ neon-db-credentials
â”‚   â””â”€ kafka-credentials (if using external Kafka)
â”œâ”€ Create ingress for frontend and backend
â””â”€ Update ConfigMaps with environment-specific values

Phase 4.3: Deploy All Services
â”œâ”€ Deploy in order:
â”‚   1. Kafka (Strimzi) - already running
â”‚   2. Dapr components
â”‚   3. Backend API
â”‚   4. Recurring Task Service
â”‚   5. Notification Service
â”‚   6. Frontend
â”œâ”€ Verify pods: kubectl get pods -n taskflow
â”œâ”€ Check logs: kubectl logs <pod-name> -c daprd
â””â”€ Test ingress: curl http://$(minikube ip)/api/health

Phase 4.4: End-to-End Testing
â”œâ”€ Test 1: Create recurring task
â”‚   â”œâ”€ Use chatbot: "Create task 'Weekly meeting' every Monday"
â”‚   â”œâ”€ Complete task
â”‚   â””â”€ Verify new task created for next Monday
â”œâ”€ Test 2: Schedule reminder
â”‚   â”œâ”€ Use chatbot: "Remind me 1 minute before task due"
â”‚   â”œâ”€ Wait 1 minute
â”‚   â””â”€ Verify notification received
â”œâ”€ Test 3: Search with Gemini
â”‚   â”œâ”€ Use chatbot: "Show high priority work tasks due this week"
â”‚   â””â”€ Verify correct results returned
â””â”€ Test 4: Chaos engineering
    â”œâ”€ Delete a pod: kubectl delete pod <recurring-task-service-pod>
    â”œâ”€ Verify K8s restarts it automatically
    â””â”€ Verify no data loss (Kafka persists events)

Phase 4.5: Documentation
â”œâ”€ Update README.md with Minikube setup instructions
â”œâ”€ Create architecture diagram (draw.io or mermaid)
â”œâ”€ Document all Dapr components
â””â”€ Create troubleshooting guide

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MILESTONE 5: Cloud Deployment (AKS/GKE/OKE)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 5.1: Cloud Provider Setup
â”œâ”€ Choose provider (recommendation: Oracle OKE - always free)
â”œâ”€ Create Kubernetes cluster:
â”‚   Oracle OKE: 4 OCPU, 24GB RAM, 3 nodes
â”œâ”€ Configure kubectl: oci ce cluster create-kubeconfig ...
â”œâ”€ Install Dapr: dapr init -k
â””â”€ Verify cluster: kubectl get nodes

Phase 5.2: Kafka Setup (Redpanda Cloud)
â”œâ”€ Sign up at redpanda.com/cloud
â”œâ”€ Create Serverless cluster (free tier)
â”œâ”€ Create topics: task-events, reminders, task-updates
â”œâ”€ Get bootstrap servers and SASL credentials
â”œâ”€ Store credentials in K8s secret:
â”‚   kubectl create secret generic kafka-credentials
â”‚     --from-literal=bootstrap-servers='...'
â”‚     --from-literal=username='...'
â”‚     --from-literal='password='...'
â””â”€ Update Dapr kafka-pubsub component with cloud credentials

Phase 5.3: Database Setup (Neon PostgreSQL)
â”œâ”€ Create Neon project at neon.tech
â”œâ”€ Create database: taskflow_prod
â”œâ”€ Run migrations (Alembic or SQL scripts)
â”œâ”€ Store connection string in K8s secret:
â”‚   kubectl create secret generic neon-db
â”‚     --from-literal=connection-string='postgresql://...'
â””â”€ Update Dapr statestore component with cloud credentials

Phase 5.4: CI/CD Pipeline (GitHub Actions)
â”œâ”€ Create .github/workflows/deploy.yml
â”œâ”€ Workflow steps:
â”‚   1. Checkout code
â”‚   2. Run tests (pytest, integration tests)
â”‚   3. Build Docker images (frontend, backend, services)
â”‚   4. Push to container registry (OCIR/ACR/GCR)
â”‚   5. Update K8s manifests with new image tags
â”‚   6. Apply manifests: kubectl apply -f k8s/
â”‚   7. Run smoke tests on deployed services
â”‚   8. Notify team on Slack (optional)
â”œâ”€ Add secrets to GitHub:
â”‚   â”œâ”€ KUBECONFIG (base64 encoded)
â”‚   â”œâ”€ DOCKER_USERNAME
â”‚   â””â”€ DOCKER_PASSWORD
â””â”€ Test pipeline: Push to main branch â†’ verify deployment

Phase 5.5: Ingress and TLS Setup
â”œâ”€ Install NGINX Ingress Controller:
â”‚   kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
â”œâ”€ Install cert-manager for Let's Encrypt:
â”‚   kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
â”œâ”€ Create ClusterIssuer for Let's Encrypt
â”œâ”€ Update Ingress with TLS config:
â”‚   tls:
â”‚     - hosts: [taskflow.your-domain.com]
â”‚       secretName: taskflow-tls
â””â”€ Verify HTTPS: https://taskflow.your-domain.com

Phase 5.6: Monitoring and Logging
â”œâ”€ Install Prometheus + Grafana:
â”‚   helm install prometheus prometheus-community/kube-prometheus-stack
â”œâ”€ Create Grafana dashboards:
â”‚   â”œâ”€ Pod CPU/Memory usage
â”‚   â”œâ”€ Kafka message throughput
â”‚   â”œâ”€ API response times
â”‚   â””â”€ Error rates
â”œâ”€ Install Loki for log aggregation:
â”‚   helm install loki grafana/loki-stack
â”œâ”€ Configure alerts:
â”‚   â”œâ”€ High error rate (>5%)
â”‚   â”œâ”€ Pod restart >3 times/hour
â”‚   â””â”€ Kafka consumer lag >1000 messages
â””â”€ Add Jaeger for distributed tracing (optional)

Phase 5.7: Final Testing
â”œâ”€ Load test: 1000 concurrent chatbot sessions
â”œâ”€ Disaster recovery test:
â”‚   â”œâ”€ Delete all pods
â”‚   â”œâ”€ Verify K8s restarts them
â”‚   â””â”€ Verify no data loss (Kafka + Neon persistence)
â”œâ”€ Security scan: trivy image scan
â””â”€ Performance test: API response time <500ms (p95)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MILESTONE 6: Documentation and Demo
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Phase 6.1: Code Documentation
â”œâ”€ Add docstrings to all functions
â”œâ”€ Generate API documentation (FastAPI /docs)
â”œâ”€ Document Dapr component configurations
â”œâ”€ Create architecture diagrams (draw.io)
â””â”€ Update CLAUDE.md with Claude Code workflow

Phase 6.2: Demo Video (90 seconds)
â”œâ”€ Script (60 seconds content + 30 seconds buffer):
â”‚   [0-10s] Show chatbot creating recurring task
â”‚   [10-20s] Complete task â†’ show new task auto-created
â”‚   [20-30s] Schedule reminder â†’ show notification
â”‚   [30-45s] Natural language search with Gemini
â”‚   [45-55s] Kubernetes dashboard (pods, services)
â”‚   [55-60s] Kafka topics with events flowing
â”œâ”€ Recording tools: OBS Studio / Loom
â”œâ”€ Editing: Cut to 90 seconds exactly
â””â”€ Upload to YouTube (unlisted link for judges)

Phase 6.3: Repository Finalization
â”œâ”€ Clean up code (remove debug logs, TODOs)
â”œâ”€ Organize folder structure:
â”‚   /specs - Specifications from all phases
â”‚   /k8s - Kubernetes manifests
â”‚   /dapr-components - Dapr configurations
â”‚   /backend - FastAPI + MCP
â”‚   /frontend - Next.js chatbot
â”‚   /services - Recurring Task, Notification services
â”‚   /tests - Unit and integration tests
â”‚   /.github/workflows - CI/CD pipeline
â”œâ”€ Update README.md:
â”‚   â”œâ”€ Project overview
â”‚   â”œâ”€ Architecture diagram
â”‚   â”œâ”€ Setup instructions (Minikube + Cloud)
â”‚   â”œâ”€ Deployment URLs
â”‚   â””â”€ Demo video link
â””â”€ Final commit: "Phase V: Advanced Cloud Deployment Complete"

Phase 6.4: Submission Checklist
â–¡ GitHub repo URL
â–¡ /specs folder with all specifications
â–¡ CLAUDE.md with Claude Code instructions
â–¡ README.md with comprehensive documentation
â–¡ Deployed URLs:

Frontend: https://taskflow.your-domain.com
Backend API: https://api.taskflow.your-domain.com/docs
â–¡ Demo video (max 90 seconds)
â–¡ WhatsApp number for presentation invitation

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ESTIMATED TIMELINE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Advanced Features (Recurring, Reminders, Search)
- Event-Driven Architecture (Kafka + Microservices)
- Dapr Integration (Pub/Sub, State, Jobs, Secrets)
- Local Deployment (Minikube + Full Testing)
- Cloud Deployment (AKS/GKE/OKE + CI/CD + Monitoring)
- Documentation and Demo Video
RISK MITIGATION:

Kafka issues? Switch to RabbitMQ via Dapr config change
Gemini rate limits? Add request queue and exponential backoff
Cloud costs? Use Oracle OKE (always free) instead of Azure/GCP
Time constraint? Reduce scope (skip Audit Service)

## Response snapshot

**Phase 0 - Research Completed:**
- R1: Dapr Jobs API - One-time jobs at `/v1.0-alpha1/jobs/` with callback endpoint
- R2: Strimzi Kafka - Ephemeral 1-broker cluster with 3 topics (3 partitions each)
- R3: Redpanda Cloud - SASL auth, store credentials in K8s secrets
- R4: WebSocket - Notification Service exposes `/ws/notifications` endpoint
- R5: PostgreSQL Arrays - `text[]` with GIN index for `@>` containment queries

**Phase 1 - Design Artifacts Created:**
- Data Model: Task, Reminder, AuditLogEntry entities with SQLAlchemy models
- OpenAPI Contract: 20 endpoints for tasks, reminders, chat, health
- Kafka Events: 14 event types across 3 topics (task-events, reminders, task-updates)
- Quickstart Guide: Minikube, Dapr, Strimzi, PostgreSQL setup instructions
- Agent Context: CLAUDE.md updated with Python 3.11 + FastAPI + Dapr + Kafka tech stack

**Constitution Gates - All Passed:**
1. âœ… Testable acceptance criteria defined
2. âœ… All research unknowns resolved
3. âœ… Data model complete with relationships
4. âœ… API contracts generated
5. âœ… No external service dependencies blocking local dev
6. âœ… Single-user demo mode - no auth complexity
7. âœ… Documentation standards met

## Outcome

- âœ… Impact: Complete Phase V implementation plan with 6 milestones, 24 phases, and 100+ tasks
- ğŸ§ª Tests: N/A - planning phase, no tests run
- ğŸ“ Files: 7 artifacts created (plan.md, research.md, data-model.md, quickstart.md, openapi.yaml, events.yaml, CLAUDE.md updated)
- ğŸ” Next prompts: `/sp.tasks` to generate dependency-ordered task list
- ğŸ§  Reflection: Research-first approach successfully resolved all technical unknowns before design. Constitution gates validated completeness before proceeding.

## Evaluation notes (flywheel)

- Failure modes observed: N/A - planning phase successful
- Graders run and results (PASS/FAIL): N/A
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): N/A
